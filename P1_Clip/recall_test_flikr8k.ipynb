{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e97c97-e0f2-4650-8484-6828f18831d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7442204",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"..\\\\..\\\\datasets\\\\\"\n",
    "models = \"..\\\\..\\\\models\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127084cc-5fa7-4237-9aa8-7ff069f03ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_model = torch.load(f\"{models}/caption_features_flickr8k.pt\")\n",
    "image_model = torch.load(f\"{models}/image_features_flickr8k.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50e68a-7116-4f83-8281-3600840f9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = list(image_model.keys())\n",
    "image_embs = torch.stack([v.squeeze(0) for v in image_model.values()])  # [8000, 512]\n",
    "\n",
    "caption_img_names = list(caption_model.keys())\n",
    "caption_embs = torch.stack(list(caption_model.values()))  # [8000, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cbf669-4702-4942-ba73-0376c3680ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_embs = caption_embs.squeeze(1)\n",
    "image_embs = image_embs.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae892189-325d-4b46-ba07-ef224b528d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"caption_embs shape:\", caption_embs.shape)   # should be [num_captions, 512]\n",
    "print(\"image_embs shape:\", image_embs.shape)       # should be [num_images, 512]\n",
    "print(\"caption_embs[0] shape:\", caption_embs[0].shape)  # should be [512]\n",
    "print(\"caption_embs[0].unsqueeze(0) shape:\", caption_embs[0].unsqueeze(0).shape)  # [1,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embs = image_embs.to(device)\n",
    "caption_embs = caption_embs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2320cc-4c99-4671-81f3-71caf44bc1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to image Recall\n",
    "def text_to_image_recall(image_embs, caption_embs, caption_img_names, image_names, K=10):\n",
    "    recalls = 0\n",
    "    total = len(caption_embs)\n",
    "\n",
    "    for i in range(total):\n",
    "        sims = F.cosine_similarity(caption_embs[i].unsqueeze(0), image_embs).squeeze()\n",
    "        topk = sims.topk(K).indices\n",
    "        \n",
    "        retrieved_imgs = [image_names[j] for j in topk]\n",
    "        true_img = caption_img_names[i]\n",
    "\n",
    "        if true_img in retrieved_imgs:\n",
    "            recalls += 1\n",
    "\n",
    "    print(f\"Text to Image Recall@{K}: {recalls/total:.4f}\")\n",
    "    return recalls / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9d728-be10-4608-85d6-d166d6f6c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image to text Recall\n",
    "def image_to_text_recall(image_embs, caption_embs, caption_img_names, image_names, K=10):\n",
    "    recalls = 0\n",
    "    total = len(image_embs)\n",
    "\n",
    "    for i in range(total):\n",
    "        sims = F.cosine_similarity( image_embs[i].unsqueeze(0), caption_embs).squeeze()\n",
    "        topk = sims.topk(K).indices\n",
    "        \n",
    "        retrieved_captions = [caption_img_names[j] for j in topk]\n",
    "        true_caption = image_names[i]\n",
    "\n",
    "        if true_caption in retrieved_captions:\n",
    "            recalls += 1\n",
    "\n",
    "    print(f\"Image to Text Recall@{K}: {recalls/total:.4f}\")\n",
    "    return recalls / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b846176-0231-4a07-b826-9207c13ede98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1, 5, 10]:\n",
    "    text_to_image_recall(image_embs, caption_embs, caption_img_names, image_names, K=k)\n",
    "\n",
    "for k in [1, 5, 10]:\n",
    "    image_to_text_recall(image_embs, caption_embs, caption_img_names, image_names, K=k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
